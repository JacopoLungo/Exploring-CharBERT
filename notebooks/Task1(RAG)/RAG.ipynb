{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpQvo0P6oP5p"
      },
      "source": [
        "## Preliminary instructions and installation of dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_W54jMD47Kj",
        "outputId": "99b6a658-e19b-4e07-f367-177789871528"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'CharBERT'...\n",
            "remote: Enumerating objects: 356, done.\u001b[K\n",
            "remote: Counting objects: 100% (167/167), done.\u001b[K\n",
            "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
            "remote: Total 356 (delta 88), reused 111 (delta 46), pack-reused 189\u001b[K\n",
            "Receiving objects: 100% (356/356), 3.31 MiB | 12.47 MiB/s, done.\n",
            "Resolving deltas: 100% (189/189), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/edoppiap/CharBERT.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT5PXlQgEF-N",
        "outputId": "4b6f10d1-ec26-4e96-ba88-b6c1a064da72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7LwNdVA-FLQ",
        "outputId": "710d8b90-de3f-4f7f-88f6-8c87960c8d9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/CharBERT\n"
          ]
        }
      ],
      "source": [
        "cd /content/CharBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMZneKwzjoYs"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install --q boto3 GitPython langchain chromadb sentence_transformers\n",
        "%pip install langchain_community==0.0.16\n",
        "!pip -q install google-generativeai==0.3.1\n",
        "!pip -q install google-ai-generativelanguage==0.4.0\n",
        "!pip -q install langchain-google-genai\n",
        "!pip install langchain==0.1.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxzT41wtjrjS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from git import Repo\n",
        "from google.colab import userdata\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.document_loaders.generic import GenericLoader\n",
        "from langchain_community.document_loaders.parsers import LanguageParser\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.text_splitter import Language\n",
        "\n",
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "\n",
        "from modeling.modeling_charbert import CharBertTransformer\n",
        "from modeling.charbert_embeddings import CharBertEmbeddings\n",
        "from sentence_transformers import SentenceTransformer, models\n",
        "\n",
        "import google.generativeai as genai\n",
        "from langchain_google_genai import GoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwmxWvM_AMdr"
      },
      "source": [
        "## Download and parse the Github repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAsgN78-AMV4"
      },
      "outputs": [],
      "source": [
        "# Clone a github repo\n",
        "repo_path = \"/content/CharBERT/db_charbert\"\n",
        "#github_repo = \"https://github.com/mawentao277/CharBERT\" ## any github repository URL\n",
        "github_repo = 'https://github.com/edoppiap/casl_labs'\n",
        "repo = Repo.clone_from(github_repo, to_path=repo_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwLXrR9LAL8l",
        "outputId": "c91bb77b-8ecf-4b53-8e4f-72d0fdaec4b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "118"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load\n",
        "loader = GenericLoader.from_filesystem(\n",
        "    #repo_path + \"/libs/langchain/langchain\",\n",
        "    repo_path,\n",
        "    glob=\"**/*\",\n",
        "    suffixes=[\".py\"],\n",
        "    #exclude=[\"**/non-utf8-encoding.py\"],\n",
        "    parser=LanguageParser(language=Language.PYTHON),\n",
        ")\n",
        "documents = loader.load()\n",
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7yHDrl3GV6C"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "pattern = r'(?:def|class)\\s+(\\w+)\\s*'\n",
        "\n",
        "i_to_del = []\n",
        "\"\"\"for i, doc in enumerate(documents):\n",
        "    matches = re.findall(pattern, doc.page_content)\n",
        "    doc.metadata['wrap_name'] = doc.metadata['source'] + '_' + matches[0]\n",
        "    if doc.metadata['content_type'] == 'simplified_code':\n",
        "        i_to_del.append(i)\"\"\"\n",
        "\n",
        "for i, doc in enumerate(documents):\n",
        "\n",
        "    if 'content_type' in doc.metadata:\n",
        "        matches = re.findall(pattern, doc.page_content)\n",
        "\n",
        "        if len(matches) == 0:\n",
        "            i_to_del.append(i)\n",
        "\n",
        "        else:\n",
        "            doc.metadata['wrap_name'] = doc.metadata['source'] + '_' + matches[0]\n",
        "            if doc.metadata['content_type'] == 'simplified_code':\n",
        "                i_to_del.append(i)\n",
        "\n",
        "    else:\n",
        "        i_to_del.append(i)\n",
        "\n",
        "for ix in reversed(i_to_del):\n",
        "    documents.pop(ix)\n",
        "\n",
        "for doc in documents:\n",
        "    print(doc.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjOWKDD0BnlS",
        "outputId": "eb0791d6-1ec9-4aa1-b3c7-4ca213a1367b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "261"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "    language=Language.PYTHON, chunk_size=1000, chunk_overlap=0\n",
        ")\n",
        "texts = python_splitter.split_documents(documents)\n",
        "len(texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx_6Gn-Gpa48"
      },
      "source": [
        "## Inizialize CharBert model for Sentence Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVqeqw8x-HX2",
        "outputId": "be74e06c-d492-4b11-f6c9-8eedcb346cd2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cls: <class 'modeling.configuration_bert.BertConfig'>\n",
            "pretrained_model_name_or_path: /content/drive/MyDrive/NLP_Project/CharBERT/charbert-bert-wiki\n",
            "cls.pretrained_config_archive_map: {'bert-base-uncased': 'https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json', 'bert-large-uncased': 'https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json', 'bert-base-cased': 'https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json', 'bert-large-cased': 'https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-config.json', 'bert-base-multilingual-uncased': 'https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-config.json', 'bert-base-multilingual-cased': 'https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json', 'bert-base-chinese': 'https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json', 'bert-base-german-cased': 'https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-cased-config.json', 'bert-large-uncased-whole-word-masking': 'https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-config.json', 'bert-large-cased-whole-word-masking': 'https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-config.json', 'bert-large-uncased-whole-word-masking-finetuned-squad': 'https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-finetuned-squad-config.json', 'bert-large-cased-whole-word-masking-finetuned-squad': 'https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-finetuned-squad-config.json', 'bert-base-cased-finetuned-mrpc': 'https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-finetuned-mrpc-config.json', 'bert-base-german-dbmdz-cased': 'https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-cased-config.json', 'bert-base-german-dbmdz-uncased': 'https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-uncased-config.json', 'bert-base-japanese': 'https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-config.json', 'bert-base-japanese-whole-word-masking': 'https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-whole-word-masking-config.json', 'bert-base-japanese-char': 'https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-char-config.json', 'bert-base-japanese-char-whole-word-masking': 'https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-char-whole-word-masking-config.json', 'bert-base-finnish-cased-v1': 'https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-cased-v1/config.json', 'bert-base-finnish-uncased-v1': 'https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-uncased-v1/config.json'}\n"
          ]
        }
      ],
      "source": [
        "charBertTransformer = CharBertTransformer(model_type = 'bert',\n",
        "                                          model_name_or_path = '/content/drive/MyDrive/NLP_Project/CharBERT/charbert-bert-wiki', ## download it from the link in the readme\n",
        "                                          char_vocab = '/content/CharBERT/data/dict/bert_char_vocab')\n",
        "\n",
        "pooling_model = models.Pooling(charBertTransformer.get_word_embedding_dimension()*2)\n",
        "embeddings = SentenceTransformer(modules=[charBertTransformer, pooling_model])\n",
        "sentenceEmbeddings = CharBertEmbeddings(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRPmlDCFpyGi"
      },
      "source": [
        "## Create a chroma vector database given the github repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgqXAo4-_B4n"
      },
      "outputs": [],
      "source": [
        "db = Chroma.from_documents(texts , sentenceEmbeddings, persist_directory='./chroma_db')\n",
        "\n",
        "retriever = db.as_retriever(\n",
        "    search_type=\"mmr\",  # Also test \"similarity\"\n",
        "    search_kwargs={\"k\": 6},\n",
        ")\n",
        "db.persist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVkrRdHDqe0c"
      },
      "source": [
        "## Load an existing vector database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJQ2p0MwW2D6"
      },
      "outputs": [],
      "source": [
        "db = Chroma(persist_directory='/content/drive/MyDrive/NLP_Project/db/casl_ema_chroma_db_giusto', embedding_function=sentenceEmbeddings)\n",
        "retriever = db.as_retriever(\n",
        "    search_type=\"mmr\",  # Also test \"similarity\"\n",
        "    search_kwargs={\"k\": 10},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAhNEjJlrEIQ"
      },
      "source": [
        "## Initialize Google gemini environment and LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pX1jNEVXWM5l"
      },
      "outputs": [],
      "source": [
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDVRweStnbEJUjEAV9Mah2ZhEUp2kz0w2M\"\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "llm = GoogleGenerativeAI(model=\"models/gemini-1.0-pro-001\")\n",
        "llm_latest = GoogleGenerativeAI(model=\"models/gemini-1.0-pro-latest\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpJhC_23WTjc"
      },
      "source": [
        "# RAG MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VDMzXuAWdxN"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "from IPython.display import display\n",
        "\n",
        "template = \"\"\"\n",
        "You are an AI assistant that helps users understand Github repositories\n",
        "that are provided to you via context input,\n",
        "the context you are given is composed by python scripts of the repository: {repo} |\n",
        "This documents are the context input Docs: {context} |\n",
        "This is the question you are going to aswer: {question}\n",
        "\n",
        "Instructions:\n",
        "1. Answer based on the documents given in the context, use only the functions seen in the context.\n",
        "2. Focus on repo/code.\n",
        "3. Consider:\n",
        "    a. Purpose/features - describe.\n",
        "    b. Functions/code - provide details/samples.\n",
        "    c. Setup/usage - give instructions.\n",
        "4. Unsure? Say \"I am not sure\".\n",
        "5. Tell me if you used the context to answer the question.\n",
        "6. Tell me from which documents/function_classes in the context you took the answer using the index of the documents in the list of documents.\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"repo\",\"question\", \"context\"]\n",
        ")\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "def retrieve_documents(question=None, retriever=None, llm=None, what_retrieve='chunks', transform_in_code=False):\n",
        "  if question == None:\n",
        "    print('Need a question to retrieve documents')\n",
        "    return None\n",
        "\n",
        "  if retriever == None:\n",
        "    print('Need retriever to retrieve documents')\n",
        "    return None\n",
        "\n",
        "  if what_retrieve == 'functions_or_classes':\n",
        "    if transform_in_code:\n",
        "      if llm:\n",
        "        code_query = get_code_from_question(question, llm)\n",
        "        print(f\"This is the code query generated from the LLM:\\n {code_query}\\n----------------------\\n\")\n",
        "      documents = retriever.get_relevant_documents(code_query)\n",
        "    else:\n",
        "      documents = retriever.get_relevant_documents(question)\n",
        "    metadata = []\n",
        "    for d in documents:\n",
        "      metadata.append(d.metadata['wrap_name'])\n",
        "    metadata = set(metadata)\n",
        "    full_res = []\n",
        "    for wrap_name in metadata:\n",
        "      res = ''\n",
        "      document_list = db.get(where={\"wrap_name\": wrap_name})['documents']\n",
        "      for s in document_list:\n",
        "        res += s\n",
        "      full_res.append(res)\n",
        "    function_or_classes_list = []\n",
        "    for i, function_class_content in enumerate(full_res):\n",
        "      function_or_classes_list.append(f'Start function/class {i}: \\n'+function_class_content+f'\\nEnd function/class {i}')\n",
        "    return function_or_classes_list\n",
        "\n",
        "  elif what_retrieve == 'chunks':\n",
        "    if transform_in_code:\n",
        "      code_query = get_code_from_question(question, llm)\n",
        "      print(f\"This is the code query generated from the LLM:\\n {code_query}\\n----------------------\\n\")\n",
        "      retrieved_documents = retriever.get_relevant_documents(code_query)\n",
        "    else:\n",
        "      retrieved_documents = retriever.get_relevant_documents(question)\n",
        "  elif what_retrieve == 'entire_document':\n",
        "    if transform_in_code:\n",
        "      if llm:\n",
        "        code_query = get_code_from_question(question, llm)\n",
        "        print(f\"This is the code query generated from the LLM:\\n {code_query}\\n----------------------\\n\")\n",
        "      documents = retriever.get_relevant_documents(code_query)\n",
        "    else:\n",
        "      documents = retriever.get_relevant_documents(question)\n",
        "    metadata = []\n",
        "    for d in documents:\n",
        "      metadata.append(d.metadata['source'])\n",
        "    metadata = set(metadata)\n",
        "    document_list = []\n",
        "    for i, source in enumerate(metadata):\n",
        "      with open(source, 'r') as file:\n",
        "        file_contents = file.read()\n",
        "      document_list.append(f'Start Document {i}: \\n'+file_contents+f'\\nEnd Document {i}')\n",
        "    return document_list\n",
        "  return retrieved_documents\n",
        "\n",
        "\n",
        "def get_code_from_question(query, llm):\n",
        "  context = \"\"\"You are an AI assiantant that converts natural language in python code, return only code in your answer. This is the question: \"\"\"\n",
        "  result = llm.invoke(context+query)\n",
        "  if \"```python\\n\" in result :\n",
        "    return result.replace(\"```python\\n\", \"\").replace(\"\\n```\",\"\").replace(\"```python \\n\",\"\").replace(\"```python  \\n\",\"\")\n",
        "  else:\n",
        "    return query\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "5PyOapRXaD5d",
        "outputId": "271af814-d013-410f-975b-20caa04320b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is the code query generated from the LLM:\n",
            " import pandas as pd\n",
            "\n",
            "# Open a csv file\n",
            "df = pd.read_csv('filename.csv')\n",
            "\n",
            "# Print the contents of the csv file\n",
            "print(df)\n",
            "----------------------\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> The function `read_csv_exams_files` in the index 4 of the context is used to read a csv file using pandas.\n",
              "> \n",
              "> The function `read_csv_exams_files` reads a csv file called `input_exams_.csv` and returns a list of `Exam` objects.\n",
              "> The function uses the `pd.read_csv` function from the pandas library to read the csv file.\n",
              "> The `pd.read_csv` function takes the path to the csv file as its first argument and the separator as its second argument.\n",
              "> The `read_csv_exams_files` function uses a semicolon as the separator.\n",
              "> The function then iterates over the rows of the DataFrame and creates an `Exam` object for each row.\n",
              "> The `Exam` object has the following attributes:\n",
              "> \n",
              "> * `name`: The name of the exam.\n",
              "> * `year`: The year the exam was taken.\n",
              "> * `semester`: The semester the exam was taken.\n",
              "> * `passed`: A boolean value indicating whether the exam was passed.\n",
              "> * `tot`: The total number of points possible on the exam.\n",
              "> * `cfu`: The number of credits the exam is worth.\n",
              "> * `optional`: A boolean value indicating whether the exam is optional.\n",
              "> * `max_stud`: The maximum number of students allowed to take the exam.\n",
              "> * `grade_distr`: A list of the grades that were given on the exam.\n",
              "> \n",
              "> I used the context to answer the question."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> I am not sure, the provided context does not contain any information on how to open a csv file using pandas.\n",
              "> \n",
              "> I used the documents in the context to answer: No"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "stuff_chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=prompt, verbose=True)\n",
        "stuff_chain_latest = load_qa_chain(llm_latest, chain_type=\"stuff\", prompt=prompt, verbose=True)\n",
        "\n",
        "transform_in_code = True\n",
        "what_retrieve = 'functions_or_classes' ## entire_document, chunks, oppure functions_or_classes\n",
        "retriever = db.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": 25},) if what_retrieve == 'chunks' else db.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": 6},)\n",
        "\n",
        "question = \"hoe do you open a csv file using pandas?\"\n",
        "\n",
        "retrieved_documents = retrieve_documents(question=question, retriever=retriever, llm=llm, what_retrieve=what_retrieve, transform_in_code=transform_in_code)\n",
        "\n",
        "if what_retrieve == 'chunks':\n",
        "  stuff_answer = stuff_chain.invoke(\n",
        "    {\"repo\": repo, \"question\": question, \"input_documents\": retrieved_documents}, return_only_outputs=True)\n",
        "  stuff_answer_latest = stuff_chain_latest.invoke(\n",
        "    {\"repo\": repo, \"question\": question, \"input_documents\": retrieved_documents}, return_only_outputs=True)\n",
        "  display(to_markdown(stuff_answer['output_text']))\n",
        "  print('\\n\\n')\n",
        "  print('_______________________________________')\n",
        "  display(to_markdown(stuff_answer_latest['output_text']))\n",
        "else:\n",
        "  result = llm.invoke(template.format(repo = repo, context = retrieved_documents, question = question))\n",
        "  result_latest = llm_latest.invoke(template.format(repo = repo, context = retrieved_documents, question = question))\n",
        "  display(to_markdown(result))\n",
        "  print('\\n\\n----------------------------------\\n\\n')\n",
        "  display(to_markdown(result_latest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WzsFLbeRM6M",
        "outputId": "6d4d5c45-a93d-4378-8535-01d9df189a58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3058.75"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum = 0\n",
        "if what_retrieve != 'chunks':\n",
        "  for doc in retrieved_documents:\n",
        "    sum += len(doc)\n",
        "else:\n",
        "  for doc in retrieved_documents:\n",
        "    sum += len(doc.page_content)\n",
        "sum/4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BlrGdmqTk-O"
      },
      "outputs": [],
      "source": [
        "display(to_markdown(llm.invoke(\" \")))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
